{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ePeYcRePI8BMXOwFEkKdzy5qVHILjtif",
      "authorship_tag": "ABX9TyOSQsV/+ffgrkTYBgaFzgzY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CATS70/colab/blob/main/sam2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UsG7_uqrVKj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/facebookresearch/sam2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pFoqKKJjry0w",
        "outputId": "6e373837-d751-45ed-b37a-3d9549bd49dc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/sam2\n",
            "  Cloning https://github.com/facebookresearch/sam2 to /tmp/pip-req-build-xafk3pt0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/sam2 /tmp/pip-req-build-xafk3pt0\n",
            "  Resolved https://github.com/facebookresearch/sam2 to commit 2b90b9f5ceec907a1c18123530e92e794ad901a4\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (0.20.1+cu124)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (1.26.4)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (4.67.1)\n",
            "Collecting hydra-core>=1.3.2 (from SAM-2==1.0)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting iopath>=0.1.10 (from SAM-2==1.0)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (11.1.0)\n",
            "Collecting omegaconf<2.4,>=2.2 (from hydra-core>=1.3.2->SAM-2==1.0)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.3.2->SAM-2==1.0)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (24.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.10->SAM-2==1.0) (4.12.2)\n",
            "Collecting portalocker (from iopath>=0.1.10->SAM-2==1.0)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.5.1->SAM-2==1.0) (1.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4,>=2.2->hydra-core>=1.3.2->SAM-2==1.0) (6.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.5.1->SAM-2==1.0) (3.0.2)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m112.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: SAM-2, antlr4-python3-runtime, iopath\n",
            "  Building wheel for SAM-2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for SAM-2: filename=sam_2-1.0-cp311-cp311-linux_x86_64.whl size=183621 sha256=36a7009c00421b59c897bf92f4a967c5d84d4dd9858f494c8066addf0bb6de93\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-j874986t/wheels/95/9c/48/520c4e55154f8bdfb2d4b52321b1d3f2fefbf4baf68c95b643\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=e0528a7fb3bd59153944fa3ea60b15ff170d7c6472fdc9a91642317a72f06c27\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31528 sha256=228ac4b2fe99d6760e47ade7896d5b70325bcd6b8d5da978e06dee21710036e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n",
            "Successfully built SAM-2 antlr4-python3-runtime iopath\n",
            "Installing collected packages: antlr4-python3-runtime, portalocker, omegaconf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, iopath, hydra-core, nvidia-cusolver-cu12, SAM-2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed SAM-2-1.0 antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 iopath-0.1.10 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 omegaconf-2.3.0 portalocker-3.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "b92753de4fbd4761b100104297998fd7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Application de segmentation d'objets parasites avec SAM2\n",
        "# Pour Google Colab Pro\n",
        "\n",
        "\n",
        "# Monter Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Imports\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sam2.build_sam2 import sam_model_registry\n",
        "from sam2.predictor import SamPredictor\n",
        "from IPython.display import display, HTML\n",
        "import gradio as gr\n",
        "from google.colab import files\n",
        "import json\n",
        "from datetime import datetime\n",
        "import io\n",
        "from PIL import Image\n",
        "import base64\n",
        "\n",
        "# Configuration pour télécharger le modèle SAM2\n",
        "SAM2_CHECKPOINT = \"/content/drive/MyDrive/MSPR/models/sam2_b.pt\"\n",
        "MODEL_TYPE = \"vit_b\"\n",
        "\n",
        "# Télécharger le modèle SAM2 si nécessaire\n",
        "if not os.path.exists(SAM2_CHECKPOINT):\n",
        "    !wget https://dl.fbaipublicfiles.com/segment_anything_2/sam2_b.pt\n",
        "\n",
        "# Initialiser le modèle SAM2\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "sam = sam_model_registry[MODEL_TYPE](checkpoint=SAM2_CHECKPOINT)\n",
        "sam.to(device=device)\n",
        "predictor = SamPredictor(sam)\n",
        "\n",
        "# Classe pour gérer notre catalogue d'objets parasites\n",
        "class ParasiteObjectCatalog:\n",
        "    def __init__(self, save_dir=\"catalog\"):\n",
        "        self.save_dir = save_dir\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.makedirs(save_dir)\n",
        "        self.catalog = self._load_catalog()\n",
        "\n",
        "    def _load_catalog(self):\n",
        "        catalog_file = os.path.join(self.save_dir, \"catalog.json\")\n",
        "        if os.path.exists(catalog_file):\n",
        "            with open(catalog_file, \"r\") as f:\n",
        "                return json.load(f)\n",
        "        return {\"objects\": []}\n",
        "\n",
        "    def save_catalog(self):\n",
        "        catalog_file = os.path.join(self.save_dir, \"catalog.json\")\n",
        "        with open(catalog_file, \"w\") as f:\n",
        "            json.dump(self.catalog, f, indent=2)\n",
        "\n",
        "    def add_object(self, image_path, mask, label, bbox):\n",
        "        # Sauvegarder le masque comme image\n",
        "        mask_id = f\"{len(self.catalog['objects'])}\"\n",
        "        mask_filename = f\"mask_{mask_id}.png\"\n",
        "        mask_path = os.path.join(self.save_dir, mask_filename)\n",
        "\n",
        "        # Convertir le masque en image et sauvegarder\n",
        "        mask_img = (mask * 255).astype(np.uint8)\n",
        "        cv2.imwrite(mask_path, mask_img)\n",
        "\n",
        "        # Extraire la portion d'image correspondant à l'objet\n",
        "        x1, y1, x2, y2 = bbox\n",
        "        image = cv2.imread(image_path)\n",
        "        object_img = image[y1:y2, x1:x2]\n",
        "        object_filename = f\"object_{mask_id}.png\"\n",
        "        object_path = os.path.join(self.save_dir, object_filename)\n",
        "        cv2.imwrite(object_path, object_img)\n",
        "\n",
        "        # Ajouter l'information au catalogue\n",
        "        obj_info = {\n",
        "            \"id\": mask_id,\n",
        "            \"label\": label,\n",
        "            \"image_source\": image_path,\n",
        "            \"mask_file\": mask_filename,\n",
        "            \"object_file\": object_filename,\n",
        "            \"bbox\": bbox,\n",
        "            \"date_added\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        }\n",
        "\n",
        "        self.catalog[\"objects\"].append(obj_info)\n",
        "        self.save_catalog()\n",
        "        return mask_id\n",
        "\n",
        "    def get_catalog_summary(self):\n",
        "        labels = {}\n",
        "        for obj in self.catalog[\"objects\"]:\n",
        "            label = obj[\"label\"]\n",
        "            if label in labels:\n",
        "                labels[label] += 1\n",
        "            else:\n",
        "                labels[label] = 1\n",
        "\n",
        "        return {\n",
        "            \"total_objects\": len(self.catalog[\"objects\"]),\n",
        "            \"labels\": labels\n",
        "        }\n",
        "\n",
        "# Fonction pour explorer Google Drive et obtenir la structure des dossiers\n",
        "def explore_drive_folders(base_path=\"/content/drive/MyDrive/MSPR/empreintes\", filter_extensions=['.jpg', '.jpeg', '.png']):\n",
        "    \"\"\"\n",
        "    Explore les dossiers dans Google Drive et renvoie une structure d'arborescence\n",
        "    avec les dossiers et les fichiers d'images.\n",
        "    \"\"\"\n",
        "    result = {}\n",
        "\n",
        "    # Vérifier si le chemin existe\n",
        "    if not os.path.exists(base_path):\n",
        "        return {\"error\": f\"Le chemin {base_path} n'existe pas\"}\n",
        "\n",
        "    # Explorer les dossiers\n",
        "    for root, dirs, files in os.walk(base_path):\n",
        "        # Ne conserver que les fichiers image\n",
        "        image_files = [f for f in files if any(f.lower().endswith(ext) for ext in filter_extensions)]\n",
        "\n",
        "        if image_files:  # Conserver seulement les dossiers avec des images\n",
        "            rel_path = os.path.relpath(root, base_path)\n",
        "            if rel_path == '.':\n",
        "                rel_path = ''\n",
        "\n",
        "            # Créer la structure de chemin dans le dictionnaire\n",
        "            current = result\n",
        "            if rel_path:\n",
        "                parts = rel_path.split(os.sep)\n",
        "                for i, part in enumerate(parts):\n",
        "                    if part not in current:\n",
        "                        current[part] = {}\n",
        "                    current = current[part]\n",
        "\n",
        "            # Ajouter les fichiers image\n",
        "            current['__files__'] = [os.path.join(root, f) for f in image_files]\n",
        "\n",
        "    return result\n",
        "\n",
        "# Initialiser notre catalogue\n",
        "catalog = ParasiteObjectCatalog(save_dir=\"/content/drive/MyDrive/MSPR/parasite_catalog\")\n",
        "\n",
        "# Fonction pour traiter une image avec SAM2\n",
        "def process_image_with_sam2(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    predictor.set_image(image)\n",
        "    return image\n",
        "\n",
        "# Fonction pour générer des masques à partir de points\n",
        "def generate_masks_from_points(image, points, point_labels):\n",
        "    masks, scores, logits = predictor.predict(\n",
        "        point_coords=np.array(points),\n",
        "        point_labels=np.array(point_labels),\n",
        "        multimask_output=True,\n",
        "    )\n",
        "    return masks, scores\n",
        "\n",
        "# Interface Gradio pour l'application\n",
        "def create_segmentation_app():\n",
        "    # Variables globales pour stocker l'état\n",
        "    current_image_path = None\n",
        "    current_image = None\n",
        "    current_masks = None\n",
        "    current_scores = None\n",
        "    selected_mask_idx = 0\n",
        "    drive_folder_structure = None\n",
        "    current_folder_path = \"/content/drive/MyDrive\"\n",
        "\n",
        "    # Fonction pour naviguer dans les dossiers Google Drive\n",
        "    def load_drive_folders():\n",
        "        nonlocal drive_folder_structure, current_folder_path\n",
        "        drive_folder_structure = explore_drive_folders(base_path=\"/content/drive/MyDrive/MSPR/empreintes\")\n",
        "        return \"Structure de Google Drive chargée. Naviguez dans vos dossiers pour trouver vos images d'empreintes.\"\n",
        "\n",
        "    # Fonction pour afficher les sous-dossiers et fichiers du dossier actuel\n",
        "    def get_folder_contents(folder_path):\n",
        "        nonlocal drive_folder_structure, current_folder_path\n",
        "\n",
        "        if folder_path == \"..\":  # Remonter d'un niveau\n",
        "            current_folder_path = os.path.dirname(current_folder_path)\n",
        "            if current_folder_path == \"/content/drive\":\n",
        "                current_folder_path = \"/content/drive/MyDrive\"\n",
        "        else:\n",
        "            current_folder_path = folder_path\n",
        "\n",
        "        # Explorer le dossier actuel\n",
        "        contents = {\"folders\": [], \"files\": []}\n",
        "\n",
        "        for item in os.listdir(current_folder_path):\n",
        "            item_path = os.path.join(current_folder_path, item)\n",
        "            if os.path.isdir(item_path):\n",
        "                contents[\"folders\"].append({\"name\": item, \"path\": item_path})\n",
        "            elif any(item.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png']):\n",
        "                contents[\"files\"].append({\"name\": item, \"path\": item_path})\n",
        "\n",
        "        # Préparer les options pour le dropdown\n",
        "        folder_options = [{\"name\": \"..\", \"path\": \"..\"}] + sorted(contents[\"folders\"], key=lambda x: x[\"name\"])\n",
        "        file_options = sorted(contents[\"files\"], key=lambda x: x[\"name\"])\n",
        "\n",
        "        return current_folder_path, folder_options, file_options\n",
        "\n",
        "    # Fonction pour sélectionner un dossier\n",
        "    def select_folder(folder_path):\n",
        "        _, folder_options, file_options = get_folder_contents(folder_path)\n",
        "        folder_names = [f\"{folder['name']} (dossier)\" for folder in folder_options]\n",
        "        file_names = [f\"{file['name']} (fichier)\" for file in file_options]\n",
        "\n",
        "        return gr.Dropdown.update(choices=folder_names + file_names,\n",
        "                                  value=None,\n",
        "                                  label=f\"Contenu de {folder_path}\")\n",
        "\n",
        "    # Fonction pour sélectionner une image\n",
        "    def select_item(item_name, folder_contents_dropdown):\n",
        "        nonlocal current_image_path, current_image\n",
        "\n",
        "        # Retrouver le chemin complet basé sur la sélection\n",
        "        selected_item = item_name.split(\" (\")[0]  # Enlever le suffixe (dossier) ou (fichier)\n",
        "        item_type = \"dossier\" if \"(dossier)\" in item_name else \"fichier\"\n",
        "\n",
        "        if item_type == \"dossier\":\n",
        "            # Naviguer vers ce dossier\n",
        "            for folder in folder_contents_dropdown:\n",
        "                if folder[\"name\"] == selected_item:\n",
        "                    return select_folder(folder[\"path\"]), None, \"Navigation vers le dossier: \" + selected_item\n",
        "        else:\n",
        "            # Charger l'image\n",
        "            for file in folder_contents_dropdown:\n",
        "                if file[\"name\"] == selected_item:\n",
        "                    image_path = file[\"path\"]\n",
        "                    current_image_path = image_path\n",
        "                    current_image = process_image_with_sam2(image_path)\n",
        "\n",
        "                    # Afficher l'image\n",
        "                    plt.figure(figsize=(10, 10))\n",
        "                    plt.imshow(current_image)\n",
        "                    plt.axis('off')\n",
        "                    plt.tight_layout()\n",
        "\n",
        "                    # Convertir le plot en image\n",
        "                    buf = io.BytesIO()\n",
        "                    plt.savefig(buf, format='png')\n",
        "                    buf.seek(0)\n",
        "                    data = base64.b64encode(buf.read()).decode('ascii')\n",
        "                    plt.close()\n",
        "\n",
        "                    return gr.Dropdown.update(), f\"data:image/png;base64,{data}\", f\"Image chargée: {selected_item}. Cliquez sur l'image pour sélectionner les objets parasites.\"\n",
        "\n",
        "        return gr.Dropdown.update(), None, \"Erreur lors de la sélection de l'élément.\"\n",
        "\n",
        "    def upload_image(image_file):\n",
        "        nonlocal current_image_path, current_image\n",
        "\n",
        "        # Sauvegarder l'image téléchargée\n",
        "        image_path = \"uploaded_image.jpg\"\n",
        "        with open(image_path, \"wb\") as f:\n",
        "            f.write(image_file)\n",
        "\n",
        "        # Traiter l'image avec SAM2\n",
        "        current_image_path = image_path\n",
        "        current_image = process_image_with_sam2(image_path)\n",
        "\n",
        "        # Afficher l'image\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.imshow(current_image)\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Convertir le plot en image\n",
        "        buf = io.BytesIO()\n",
        "        plt.savefig(buf, format='png')\n",
        "        buf.seek(0)\n",
        "        data = base64.b64encode(buf.read()).decode('ascii')\n",
        "        plt.close()\n",
        "\n",
        "        return f\"data:image/png;base64,{data}\", \"Image téléchargée avec succès. Cliquez sur l'image pour sélectionner les objets parasites.\"\n",
        "\n",
        "    def segment_from_clicks(image_data, evt: gr.SelectData):\n",
        "        nonlocal current_image, current_masks, current_scores, selected_mask_idx\n",
        "\n",
        "        if current_image is None:\n",
        "            return image_data, \"Veuillez d'abord télécharger une image.\"\n",
        "\n",
        "        # Récupérer les coordonnées du clic\n",
        "        x, y = evt.index\n",
        "        points = [[x, y]]\n",
        "        point_labels = [1]  # 1 pour foreground\n",
        "\n",
        "        # Générer les masques\n",
        "        masks, scores = generate_masks_from_points(current_image, points, point_labels)\n",
        "        current_masks = masks\n",
        "        current_scores = scores\n",
        "        selected_mask_idx = 0  # Sélectionner le premier masque par défaut\n",
        "\n",
        "        # Afficher l'image avec le masque\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.imshow(current_image)\n",
        "\n",
        "        # Superposer le masque\n",
        "        show_mask(masks[selected_mask_idx], plt.gca())\n",
        "        show_points(points, point_labels, plt.gca())\n",
        "\n",
        "        plt.title(f\"Score du masque: {scores[selected_mask_idx]:.3f}\")\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Convertir le plot en image\n",
        "        buf = io.BytesIO()\n",
        "        plt.savefig(buf, format='png')\n",
        "        buf.seek(0)\n",
        "        data = base64.b64encode(buf.read()).decode('ascii')\n",
        "        plt.close()\n",
        "\n",
        "        # Préparer les options de masque\n",
        "        mask_options = [f\"Masque {i+1} (Score: {score:.3f})\" for i, score in enumerate(scores)]\n",
        "\n",
        "        return f\"data:image/png;base64,{data}\", f\"Objet segmenté! Choisissez un masque et ajoutez-le au catalogue.\"\n",
        "\n",
        "    def change_mask(mask_idx):\n",
        "        nonlocal current_masks, current_scores, selected_mask_idx\n",
        "\n",
        "        if current_masks is None:\n",
        "            return None, \"Veuillez d'abord segmenter un objet.\"\n",
        "\n",
        "        selected_mask_idx = mask_idx\n",
        "\n",
        "        # Afficher l'image avec le masque sélectionné\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.imshow(current_image)\n",
        "\n",
        "        # Superposer le masque\n",
        "        show_mask(current_masks[selected_mask_idx], plt.gca())\n",
        "\n",
        "        plt.title(f\"Score du masque: {current_scores[selected_mask_idx]:.3f}\")\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Convertir le plot en image\n",
        "        buf = io.BytesIO()\n",
        "        plt.savefig(buf, format='png')\n",
        "        buf.seek(0)\n",
        "        data = base64.b64encode(buf.read()).decode('ascii')\n",
        "        plt.close()\n",
        "\n",
        "        return f\"data:image/png;base64,{data}\", f\"Masque {selected_mask_idx+1} sélectionné.\"\n",
        "\n",
        "    def add_to_catalog(label):\n",
        "        nonlocal current_image_path, current_masks, selected_mask_idx\n",
        "\n",
        "        if current_masks is None:\n",
        "            return \"Veuillez d'abord segmenter un objet.\"\n",
        "\n",
        "        if not label:\n",
        "            return \"Veuillez entrer une étiquette pour l'objet parasite.\"\n",
        "\n",
        "        # Récupérer le masque sélectionné\n",
        "        mask = current_masks[selected_mask_idx]\n",
        "\n",
        "        # Calculer la boîte englobante\n",
        "        y_indices, x_indices = np.where(mask)\n",
        "        x1, x2 = np.min(x_indices), np.max(x_indices)\n",
        "        y1, y2 = np.min(y_indices), np.max(y_indices)\n",
        "        bbox = [int(x1), int(y1), int(x2), int(y2)]\n",
        "\n",
        "        # Ajouter au catalogue\n",
        "        object_id = catalog.add_object(current_image_path, mask, label, bbox)\n",
        "\n",
        "        # Récupérer le résumé du catalogue\n",
        "        summary = catalog.get_catalog_summary()\n",
        "\n",
        "        return f\"Objet ajouté au catalogue avec ID: {object_id}\\n\\nRésumé du catalogue:\\n- Total d'objets: {summary['total_objects']}\\n- Étiquettes: {', '.join([f'{k} ({v})' for k, v in summary['labels'].items()])}\"\n",
        "\n",
        "    def export_catalog():\n",
        "        # Créer un zip du catalogue\n",
        "        !zip -r /content/catalog.zip /content/drive/MyDrive/MSPR/parasite_catalog\n",
        "\n",
        "        # Télécharger le zip\n",
        "        files.download('/content/catalog.zip')\n",
        "\n",
        "        return \"Catalogue exporté avec succès sous forme de fichier ZIP.\"\n",
        "\n",
        "    # Fonctions d'aide pour visualiser les masques et points\n",
        "    def show_mask(mask, ax):\n",
        "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
        "        h, w = mask.shape[-2:]\n",
        "        mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "        ax.imshow(mask_image)\n",
        "\n",
        "    def show_points(coords, labels, ax, marker_size=375):\n",
        "        pos_points = coords[labels==1]\n",
        "        neg_points = coords[labels==0]\n",
        "        ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "        ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "\n",
        "    # Création de l'interface Gradio\n",
        "    with gr.Blocks() as app:\n",
        "        gr.Markdown(\"# Application de segmentation d'objets parasites avec SAM2\")\n",
        "gr.Markdown(\"#### Utilise le modèle Meta Segment Anything 2 pour détecter et cataloguer les objets parasites dans les images d'empreintes\")\n",
        "        gr.Markdown(\"Cette application vous permet de sélectionner des objets parasites dans des images d'empreintes et de créer un catalogue pour entraîner un modèle de détection.\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                # Panneau de navigation dans Google Drive\n",
        "                load_drive_btn = gr.Button(\"Charger les dossiers Google Drive\")\n",
        "                current_path_display = gr.Textbox(label=\"Chemin actuel\", value=\"/content/drive/MyDrive/MSPR/empreintes\")\n",
        "                folder_browser = gr.Dropdown(label=\"Contenu du dossier\", choices=[], interactive=True)\n",
        "\n",
        "                # Alternative: téléchargement direct\n",
        "                gr.Markdown(\"### Ou téléchargez directement une image:\")\n",
        "                upload_btn = gr.File(label=\"Télécharger une image\")\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                # Affichage et manipulation de l'image\n",
        "                image_display = gr.Image(label=\"Image\", interactive=True)\n",
        "                status = gr.Textbox(label=\"Statut\", value=\"Sélectionnez une image pour commencer.\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    mask_selector = gr.Slider(minimum=0, maximum=2, step=1, value=0, label=\"Sélectionner un masque\", interactive=True)\n",
        "\n",
        "                with gr.Row():\n",
        "                    label_input = gr.Textbox(label=\"Étiquette de l'objet parasite\")\n",
        "                    add_btn = gr.Button(\"Ajouter au catalogue\")\n",
        "\n",
        "                catalog_status = gr.Textbox(label=\"Statut du catalogue\", value=\"Aucun objet dans le catalogue.\", lines=5)\n",
        "                export_btn = gr.Button(\"Exporter le catalogue\")\n",
        "\n",
        "        # Variables pour stocker temporairement les données du navigateur de fichiers\n",
        "        folder_contents = gr.State([])\n",
        "\n",
        "        # Événements\n",
        "        load_drive_btn.click(load_drive_folders, inputs=[], outputs=[status])\n",
        "        load_drive_btn.click(lambda: get_folder_contents(\"/content/drive/MyDrive/MSPR/empreintes\"),\n",
        "                            inputs=[],\n",
        "                            outputs=[current_path_display, folder_contents, folder_contents])\n",
        "        load_drive_btn.click(lambda x: [f\"{folder['name']} (dossier)\" for folder in x] + [f\"{file['name']} (fichier)\" for file in x],\n",
        "                            inputs=[folder_contents],\n",
        "                            outputs=[folder_browser])\n",
        "\n",
        "        folder_browser.change(select_item,\n",
        "                             inputs=[folder_browser, folder_contents],\n",
        "                             outputs=[folder_browser, image_display, status])\n",
        "\n",
        "        upload_btn.upload(upload_image, inputs=[upload_btn], outputs=[image_display, status])\n",
        "        image_display.select(segment_from_clicks, inputs=[image_display], outputs=[image_display, status])\n",
        "        mask_selector.change(change_mask, inputs=[mask_selector], outputs=[image_display, status])\n",
        "        add_btn.click(add_to_catalog, inputs=[label_input], outputs=[catalog_status])\n",
        "        export_btn.click(export_catalog, inputs=[], outputs=[catalog_status])\n",
        "\n",
        "    return app\n",
        "\n",
        "# Lancer l'application\n",
        "app = create_segmentation_app()\n",
        "app.launch(debug=True)\n",
        "\n",
        "# Instructions d'utilisation\n",
        "print(\"\"\"\n",
        "Instructions d'utilisation:\n",
        "1. Autorisez l'accès à votre Google Drive lorsque demandé\n",
        "2. Cliquez sur 'Charger les dossiers Google Drive' pour accéder à vos images\n",
        "3. Naviguez dans la structure de vos dossiers par animal et sélectionnez une image d'empreinte\n",
        "4. Cliquez sur un objet parasite dans l'image pour le segmenter avec SAM\n",
        "5. Utilisez le curseur pour sélectionner le meilleur masque parmi les options\n",
        "6. Entrez une étiquette pour l'objet parasite (ex: 'poussière', 'cheveu', etc.)\n",
        "7. Cliquez sur 'Ajouter au catalogue' pour sauvegarder l'objet\n",
        "8. Répétez pour tous les objets parasites dans l'image\n",
        "9. Utilisez 'Exporter le catalogue' pour télécharger votre catalogue complet\n",
        "\n",
        "Note: Le catalogue sera enregistré dans votre Google Drive à l'emplacement /MyDrive/parasite_catalog/\n",
        "Ce catalogue pourra être utilisé ultérieurement pour entraîner votre propre modèle de détection.\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "5_XesdOItNYt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}